{
  "trainer": {
    "loss_fn": "CrossEntropyLoss",
    "scheduler": "LambdaLR",
    "optimizer": "AdamW",
    "learning_rate": 5e-5,
    "lr_lambda": 0.99,
    "epochs": 1,
    "batch_size": 25,
    "n_logs": 10,
    "early_stop": {
      "patience": 2,
      "delta": 0
    }
  },
  "model_name": "xlm-roberta-finetune_v2_ep1",
  "architecture": "FineTune",
  "dataset": "wortschartz_31",
  "model": {
    "base_model": "xlm-roberta-base",
    "config": null
  },
  "device": "cuda"
}

